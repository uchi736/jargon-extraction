1. エグゼクティブサマリー
プロジェクト目的
RAGシステムおよび文書分類において、LLMが理解できない専門用語（未知語）を特定し、専門用語辞書を構築することで検索精度を向上させる。
基本方針

完璧を求めず、実用的な改善を段階的に実施
Perplexityベースの優先順位付けにより人手作業を最小化
小規模なパイロットから開始し、効果測定しながら拡大

2. 技術的アプローチ
2.1 専門用語候補の抽出手法
形態素解析（SudachiPy）による基礎処理

辞書モード: Cモード（最長単位）で複合語を維持
品詞フィルタリング: 名詞（専門用語の大半）を中心に抽出
未知語検出: Sudachiの辞書に存在しない語を自動検出
複合名詞の抽出: 連続する名詞を結合して専門用語候補に

TF-IDFによる重要度評価

Sudachiで分割した形態素を基にTF-IDF計算
文書集合内での重要度を統計的に評価

固有表現抽出（NER）の活用

抽出対象: 組織名、製品名、人名など
ツール: GiNZA（Sudachiベース）で日本語NER
注意点: 抽出された固有名詞を専門用語候補として扱う

パターンマッチング
日本語専門用語パターン:

カタカナ語: 連続するカタカナ（「トランスフォーマー」「ニューラルネットワーク」）
漢字+カタカナ複合: 「深層ニューラルネット」「事前学習モデル」
送り仮名付き複合語: 「教師あり学習」「教師なし学習」

英数字混在パターン:

アルファベット略語: BERT、GPT、CNN
バージョン付き: GPT-4、Python3.9
日英混在: 「BERTモデル」「Transformer構造」

2.2 LLM理解度の評価指標
Perplexityとトークン生成確率の使い分け
Perplexity:

文章全体での困惑度を表す総合指標
値が高いほどLLMが理解に困っている
複合語や文脈での理解度評価に適する
閾値目安: <30（高確信）、30-70（中程度）、>70（低確信）

トークン生成確率:

個々のトークンを生成する際の確信度
0〜1の範囲で、高いほど確信がある
単一の専門用語の理解度評価に適する

長文書でのPerplexity活用
チャンク化戦略:

粗いスキャン（500トークン単位）: 問題箇所の大まかな特定
中間スキャン（100-200トークン/段落単位）: 段落レベルでの特定
詳細スキャン（20-50トークン/文単位）: 具体的な専門用語の特定

ホットスポット検出:

Perplexityが急激に上昇する箇所を重点チェック
前後の文脈と比較して異常値を検出

2.3 優先順位付けと分類
3段階の自動分類

高確信度グループ（Perplexity < 30）: 自動承認
低確信度グループ（Perplexity > 70）: 要人手確認
中間グループ（30-70）: 保留または追加評価

優先順位の決定要因

Perplexity値 × 文書内出現頻度
高頻度かつ低確信度の用語を最優先

3. 実装フェーズ
Phase 1: 初期セットアップ（Week 1）
作業内容:

対象文書の選定（10-20ページの日本語専門文書）
SudachiPyによる形態素解析環境構築
専門用語候補の自動抽出（約1000語）

技術的準備:

SudachiPyのインストールと辞書設定
形態素解析パイプラインの構築
複合名詞抽出ルールの実装

成果物:

専門用語候補リスト
評価用スクリプト

Phase 2: LLM評価と優先順位付け（Week 2）
作業内容:

各候補用語のPerplexity計算
トークン生成確率の測定
3段階分類の実施
人手チェック対象の選定（50-100語）

評価テスト:

定義生成テスト: 「{用語}とは何か説明してください」
文脈使用テスト: 「{用語}の使用例を3つ作成」
一貫性テスト: 複数回生成での安定性確認

Phase 3: 最小限の人手アノテーション（Week 2-3）
作業内容:

低確信度グループから高頻度語を50-100語選定
各用語の人手検証:

専門用語かどうかの判定
正しい定義の作成/検証
LLM生成定義の正誤判定



作業量:

1語あたり: 30秒〜1分
100語の場合: 1-2時間で完了
必要人員: 専門知識を持つアノテーター1-2名

Phase 4: 効果測定（Week 3-4）
評価指標:

検索精度（MRR、NDCG）の向上率
エラー率の低減
専門用語カバレッジ

判断基準:

5-10%の精度向上 → 成功、拡張へ
効果限定的 → アプローチ再検討

Phase 5: 段階的拡張（Week 4以降）
Active Learningアプローチ:

初期結果を基に分類器を学習
次の不確実な50語を選定
人手アノテーション（週1-2時間）
辞書更新とモデル再学習
月次で効果測定

4. 日本語処理の具体的実装
SudachiPyを活用した専門用語抽出
複合名詞の検出:
例：「自然」「言語」「処理」→「自然言語処理」
　　「深層」「学習」→「深層学習」
未知語の特定:

Sudachi辞書にない語 = 新しい専門用語の可能性大
OOV（Out of Vocabulary）語のリスト化

品詞パターンによる抽出:

名詞の連続
名詞＋サ変動詞（「学習する」→「学習」）
カタカナ＋名詞（「ニューラルネットワーク」）

日本語特有の課題への対応
表記ゆれの統一:

「機械学習」「機械がくしゅう」「マシンラーニング」
カタカナ表記の統一（長音記号の有無など）

略語と正式名称の対応:

「自然言語処理」↔「NLP」
「深層学習」↔「ディープラーニング」↔「DL」

5. 実装上の工夫
半自動化による効率化
複数LLMの活用:

GPT-4とClaudeで定義生成
結果が一致 → 自動承認
不一致 → 人手確認対象

段階的な品質基準:

初期: 「RAGが機能する程度」の定義で十分
中期: 頻出用語の定義を精緻化
長期: 体系的な専門用語辞書へ

6. リスク管理
想定リスクと対策
リスク影響対策人手作業の負担超過高最重要20語から開始効果が限定的中早期の効果測定と方針転換専門用語の定義の曖昧性中実用性重視で完璧を求めないPerplexity閾値の不適切低運用しながら調整形態素解析の誤り中複数の分割モードで確認
7. 成功指標とマイルストーン
短期目標（1ヶ月）

 専門用語辞書100語の構築
 RAG検索精度5-10%向上
 総作業時間10時間以内

中期目標（3ヶ月）

 辞書500語への拡張
 半自動更新システムの確立
 月次メンテナンス2時間以内

8. 必要リソース
人的リソース

専門知識を持つアノテーター: 1-2名
初期投資: 10時間
継続投資: 週1-2時間

技術リソース

LLM API（GPT-4、Claude等）
日本語処理ライブラリ（SudachiPy、GiNZA）
基本的な計算環境

9. 次のアクション
即時実行項目（今週）

パイロット用日本語文書の選定
SudachiPy環境構築
最重要10語での全プロセス試行

準備項目（来週）

形態素解析パイプラインの実装
Perplexity計算環境の構築
ベースラインRAG性能の測定

10. 成功のための重要ポイント

完璧を求めない: 「動く改善」を優先
小さく始める: 10語→50語→100語と段階的に
効果測定を重視: 各段階で定量的に評価
Perplexityを活用: 人手作業を最小化する鍵
日本語の特性を考慮: 形態素解析と表記ゆれへの対応


結論: 本計画は日本語文書を対象とし、SudachiPyによる形態素解析を基盤として専門用語を抽出する。Perplexityによる優先順位付けで人手作業を最小化し、まず10語のパイロットから開始して段階的に拡大することで、着実な改善を実現する。