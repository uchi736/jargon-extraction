# 専門用語抽出・評価システム 評価ロジック仕様書

## システム概要
本システムは、日本語テキストから専門用語を自動抽出し、LLMによる評価を組み合わせて高精度な専門用語辞書を生成するシステムです。

## 主要コンポーネント

### 1. wakachigaki_eval.py (LCEL版RAG統合システム)
**目的**: LangChain Expression Language (LCEL)とRAGを使用した専門用語抽出

**主要機能**:
- SudachiPy（Mode.A）による形態素解析
- ChromaDBベクトルストアによるRAG実装
- Google Embedding API（text-embedding-004）でエンベディング生成
- Gemini-2.0-flashによる専門用語検証
- LangSmithによる処理トレース

**処理フロー**:
1. ドキュメント読み込み（PDF/DOCX/TXT/MD/HTML対応）
2. テキストを2000文字チャンクに分割（200文字オーバーラップ）
3. 全チャンクをベクトル化してChromaDBに保存
4. 各チャンクから候補語生成（SudachiPy + N-gram）
5. 類似チャンクを検索して関連文脈として活用
6. LLMで専門用語を検証・定義生成
7. 重複統合と最終出力

**評価基準**:
- 候補リストからの厳密な選定（新規追加不可）
- 関連文脈を参考にした正確な定義生成
- 一般的すぎる単語の除外

### 2. jargon_extractor.py (統合型評価システム)
**目的**: 統計的指標とLLMによる真のPerplexity計算を組み合わせた高精度評価

**主要機能**:
- SudachiPy（Mode.A）による形態素解析と複合名詞生成
- TF-IDF、C-value/NC-value統計指標計算
- Azure OpenAI GPT-4oによる真のPerplexity計算
- 3段階自動分類（高/中/低確信度）
- 段階的実行モード（pilot/limit/full）

**評価手法**:

#### 2.1 統計的評価
- **TF-IDF**: 文書内での重要度評価
- **C-value**: 専門用語らしさの統計指標
  ```
  C-value = log2(長さ) × (頻度 - 包含頻度/包含数)
  ```

#### 2.2 LLM評価（真のPerplexity）
**logprobs APIベース（利用可能な場合）**:
- 文脈での用語生成確率を直接計算
- 複数文脈での平均logprobからPerplexity算出
- 数式: `Perplexity = exp(-avg_logprob)`

**フォールバック評価（3つの手法の重み付き平均）**:
1. **定義生成の一貫性** (40%)
   - 3回の定義生成で一貫性を評価
   - 不確実性キーワード検出
2. **理解度直接評価** (30%)
   - 1-10スケールで困難度評価
3. **文脈での自然さ** (30%)
   - サンプル文脈での自然さを評価

#### 2.3 トークン生成確率
- 部分完成確率（70%）: 用語の一部から完全形を予測
- 一般性評価（30%）: 専門用語としての一般性を評価

#### 2.4 最終優先度スコア
```
priority_score = 統計スコア × 0.4 + (100 - Perplexity) × 0.4 + トークン確率 × 100 × 0.2
```

### 3. enhanced_perplexity.py (強化版Perplexity計算)
**目的**: 文脈チャンク化によるホットスポット検出と精密評価

**主要機能**:
- 段階的チャンク分析（500/100/20トークン単位）
- ホットスポット検出（平均+1.5σ以上のPerplexity）
- 複数手法による精密トークン確率計算

**評価手法**:
1. **チャンクPerplexity分析**
   - 異なるサイズでテキストを分割
   - 各チャンクのPerplexityを計算
   - 統計的外れ値をホットスポットとして検出

2. **精密トークン確率（3手法の重み付き平均）**
   - 部分完成確率（40%）
   - 文脈出現確率（40%）
   - 類似語比較確率（20%）

### 4. azure_logprobs_perplexity.py (数学的に正確なPerplexity)
**目的**: Azure OpenAI logprobs APIを使用した真のPerplexity計算

**主要機能**:
- logprobsデータの直接取得と解析
- マスク予測方式によるPerplexity計算
- 文書全体のPerplexityプロファイル作成

**評価手法**:

#### 4.1 真のPerplexity計算
```python
# 各トークンのlogprobを取得
logprobs = [token.logprob for token in response.logprobs.content]
# 平均logprobからPerplexity計算
avg_logprob = np.mean(logprobs)
perplexity = math.exp(-avg_logprob)
```

#### 4.2 マスク予測評価
- 用語を[MASK]に置換
- LLMに予測させて正解率を評価
- 予測順位からPerplexityを推定

#### 4.3 文書プロファイル
- 50%オーバーラップでチャンク分割
- 各チャンクのPerplexity計算
- ホットスポット検出（μ + 1.5σ）

### 5. mask_generation_strategies.py (文脈生成戦略)
**目的**: 専門用語評価のための多様なMASK文脈生成

**文脈生成戦略**:
1. **実文脈抽出**: 元テキストから実際の使用例を抽出
2. **テンプレート生成**: 定義/説明/計算/応用の4パターン
3. **ドメイン特化生成**: 工学/化学/AI分野別テンプレート
4. **統計的生成**: 共起パターンに基づく文脈

**品質評価基準**:
- 文脈長（10-200文字が理想）
- MASK位置（文頭・文末を避ける）
- 文法的完全性
- コンテキストの豊富さ

## 分類基準

### 高確信度（Perplexity < 30）
- 自動承認される専門用語
- 明確な定義が生成可能
- 一貫した理解が示される

### 中確信度（30 ≤ Perplexity ≤ 70）
- 保留状態の用語
- 文脈により理解度が変わる
- 追加検証が推奨される

### 低確信度（Perplexity > 70）
- 人手確認が必要な用語
- 定義が不明確または不一致
- 専門性が極めて高いか造語の可能性

## 実行モード

### Pilotモード
- 上位10語のみ処理
- 動作確認用
- 約30秒で完了

### Limitモード
- 指定数の上位語を処理
- 統計スコア順
- APIコスト管理

### Fullモード
- 上位100語まで処理（効率化のため制限）
- 本番実行用
- 約5-10分で完了

## 出力形式

### results.json
```json
{
  "metadata": {
    "input_file": "入力ファイルパス",
    "mode": "実行モード",
    "processing_time": 処理時間,
    "total_candidates": 総候補数
  },
  "classified_terms": {
    "high_confidence": [...],
    "medium_confidence": [...],
    "low_confidence": [...]
  }
}
```

### review.csv
人手確認用の候補リスト（優先度順）
- term: 専門用語
- perplexity: Perplexity値
- frequency: 出現頻度
- priority_score: 優先度スコア
- definition: 生成された定義

### stats.json
処理統計情報
- 処理時間
- 分類結果の内訳
- 自動承認率/要確認率

## 技術的特徴

### 並列処理
- 非同期処理（asyncio）による効率化
- バッチ処理でAPI呼び出しを最適化
- レート制限対策（適切なsleep）

### エラーハンドリング
- 各評価手法にフォールバック機構
- デフォルト値による安定動作
- 詳細なログ出力

### 拡張性
- モジュール化された設計
- 新しい評価手法の追加が容易
- ドメイン別カスタマイズ可能

## 推奨使用方法

1. **初期評価**: Pilotモードで動作確認
2. **統計分析**: 統計指標で候補を事前ランキング
3. **LLM評価**: 上位候補に対してPerplexity計算
4. **人手確認**: 低確信度の用語を専門家がレビュー
5. **辞書生成**: 高確信度用語で自動辞書作成

## パフォーマンス指標

- **精度**: 高確信度用語の90%以上が適切な専門用語
- **カバレッジ**: 重要な専門用語の80%以上を抽出
- **効率**: 100語あたり約5分で処理完了
- **コスト**: Azure OpenAI APIコストを最小化